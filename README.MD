# Benchmarking-Free-AI

## Overview
Welcome to the **Benchmarking-Free-AI** repository! This project is dedicated to evaluating fully free AI models accessible via their official websites, focusing on their performance across Software Development Life Cycle (SDLC) tasks. As of 05:41 PM +06 on Monday, October 20, 2025, we aim to provide a comprehensive resource for developers, researchers, and enthusiasts to identify reliable, unlimited AI tools for coding, planning, validation, and delivery—without the constraints of payments, sign-ups, or usage limits.

This repository contains curated lists, benchmarking strategies, and results to help you leverage these tools effectively. Whether you're automating a small project or exploring AI for complex workflows, this project offers insights into models that perform without barriers.

## Features
- **Curated Candidate List**: A detailed catalog of 100% free AI models with no limits, verified through 2025 sources (e.g., official docs, Reddit, Medium).
- **SDLC Focus**: Evaluations tailored to key phases—analysis, planning, execution, and delivery—using real-world tasks like code generation and documentation.
- **Open Access**: All findings and methodologies are publicly available for replication and contribution.
- **Regular Updates**: Quarterly reviews to ensure the list reflects the latest free AI offerings.

## Getting Started
### Prerequisites
- A modern web browser (e.g., Chrome) with extensions for automation (optional).
- Basic knowledge of Git for contributing or tracking updates.
- Internet access (fiber-optic recommended for optimal performance).

### Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/SANIUL-blackdragon/benchmarking-free-AI.git
   ```
2. Navigate to the project directory:
   ```bash
   cd benchmarking-free-AI
   ```
3. Explore the files:
   - `candidates.md`: List of free AI models with strengths and verification notes.
   - `results.md` (future): Benchmarking outcomes and analysis.

### Usage
- Review `candidates.md` to select models for your SDLC tasks.
- Use the suggested benchmarking strategy (outlined in future docs) to test models with ~1k tasks.
- Contribute results or updates via pull requests.

## Candidate Models
This project tracks a growing list of fully free AI models accessible via websites, with no daily limits or payments. Check `candidates.md` for the latest entries, including:
- **DeepSeek V3.1** (chat.deepseek.com): Strong in reasoning and code generation.
- **Qwen 3** (chat.qwen.ai): Efficient for execution with fewer fixing loops.
- **GLM-4.6** (chat.z.ai): Balanced performance across all SDLC phases.
- And more (e.g., Llama 3.1, Mistral Nemo, Phi-3.5, Gemma 2)!

These models support complex prompts (500-2000 tokens) and deepthink/CoT modes, ideal for SDLC automation.

## Contributing
We welcome contributions! To get involved:
1. Fork the repository.
2. Create a branch for your changes:
   ```bash
   git checkout -b feature/your-feature
   ```
3. Commit your changes:
   ```bash
   git commit -m "Add your feature or update"
   ```
4. Push to the branch:
   ```bash
   git push origin feature/your-feature
   ```
5. Open a pull request with a clear description.

Please adhere to the [Contributor Covenant Code of Conduct](CODE_OF_CONDUCT.md) (to be added).

## License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details (to be added).

## Acknowledgments
- Thanks to the open-source AI community (e.g., r/LocalLLaMA, Hugging Face) for insights.
- Appreciation to 2025 evaluators (Medium, DataCamp, arXiv) for data.
- Special thanks to contributors who keep this list alive!

## Future Plans
- Expand benchmarking with detailed results.md.
- Add scripts/tools for automated testing.
- Integrate community feedback for broader SDLC use cases.

Stay tuned by watching this repository for updates!